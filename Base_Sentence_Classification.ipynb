{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with Logistic Regression, Linear SVM, and Naive Bayes\n",
    "This notebook reads training and testing data from CSV files, preprocesses the text data, and performs classification using Logistic Regression, Linear SVM, and Naive Bayes with TF-IDF vectors. It reports the macro and micro F1 scores, accuracy, precision, recall, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data\n",
    "train_df = pd.read_csv('Dataset/preprocessed/part1/train.csv')\n",
    "val_df = pd.read_csv('Dataset/preprocessed/part1/val.csv')\n",
    "test_df = pd.read_csv('Dataset/preprocessed/part1/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 20, 21)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberize_labels(df, labels):\n",
    "    for label in labels:\n",
    "        df[label] = df[label].apply(lambda x: 1 if x == 'met' else 0)\n",
    "    return df\n",
    "\n",
    "train_df = numberize_labels(train_df, labels=['abdominal', 'creatinine', 'major_diabetes'])\n",
    "test_df = numberize_labels(test_df, labels=['abdominal', 'creatinine', 'major_diabetes'])\n",
    "val_df = numberize_labels(val_df, labels=['abdominal', 'creatinine', 'major_diabetes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine train and val for this part\n",
    "train_df = pd.concat([train_df, val_df], ignore_index=True)\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess and vectorize text data\n",
    "def preprocess_data(train_df, test_df, text_column):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train = vectorizer.fit_transform(train_df[text_column])\n",
    "    X_test = vectorizer.transform(test_df[text_column])\n",
    "    return X_train, X_test, vectorizer\n",
    "\n",
    "# Preprocess data\n",
    "X_train, X_test, vectorizer = preprocess_data(train_df, test_df, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate model\n",
    "def train_evaluate_model(X_train, X_test, y_train, y_test, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    f1_micro = f1_score(y_test, y_pred, average='micro')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision (Macro): {precision}\")\n",
    "    print(f\"Recall (Macro): {recall}\")\n",
    "    print(f\"F1 Score (Macro): {f1_macro}\")\n",
    "    print(f\"F1 Score (Micro): {f1_micro}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating label: abdominal\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.5238095238095238\n",
      "Precision (Macro): 0.275\n",
      "Recall (Macro): 0.4583333333333333\n",
      "F1 Score (Macro): 0.34374999999999994\n",
      "F1 Score (Micro): 0.5238095238095238\n",
      "Confusion Matrix:\n",
      "[[11  1]\n",
      " [ 9  0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.92      0.69        12\n",
      "           1       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.52        21\n",
      "   macro avg       0.28      0.46      0.34        21\n",
      "weighted avg       0.31      0.52      0.39        21\n",
      "\n",
      "\n",
      "Linear SVM:\n",
      "Accuracy: 0.7619047619047619\n",
      "Precision (Macro): 0.7596153846153846\n",
      "Recall (Macro): 0.75\n",
      "F1 Score (Macro): 0.7529411764705882\n",
      "F1 Score (Micro): 0.7619047619047619\n",
      "Confusion Matrix:\n",
      "[[10  2]\n",
      " [ 3  6]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80        12\n",
      "           1       0.75      0.67      0.71         9\n",
      "\n",
      "    accuracy                           0.76        21\n",
      "   macro avg       0.76      0.75      0.75        21\n",
      "weighted avg       0.76      0.76      0.76        21\n",
      "\n",
      "\n",
      "Naive Bayes:\n",
      "Accuracy: 0.5714285714285714\n",
      "Precision (Macro): 0.2857142857142857\n",
      "Recall (Macro): 0.5\n",
      "F1 Score (Macro): 0.36363636363636365\n",
      "F1 Score (Micro): 0.5714285714285714\n",
      "Confusion Matrix:\n",
      "[[12  0]\n",
      " [ 9  0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73        12\n",
      "           1       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.57        21\n",
      "   macro avg       0.29      0.50      0.36        21\n",
      "weighted avg       0.33      0.57      0.42        21\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Evaluating label: creatinine\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.6666666666666666\n",
      "Precision (Macro): 0.8157894736842105\n",
      "Recall (Macro): 0.6111111111111112\n",
      "F1 Score (Macro): 0.5689149560117301\n",
      "F1 Score (Micro): 0.6666666666666666\n",
      "Confusion Matrix:\n",
      "[[12  0]\n",
      " [ 7  2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      1.00      0.77        12\n",
      "           1       1.00      0.22      0.36         9\n",
      "\n",
      "    accuracy                           0.67        21\n",
      "   macro avg       0.82      0.61      0.57        21\n",
      "weighted avg       0.79      0.67      0.60        21\n",
      "\n",
      "\n",
      "Linear SVM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n",
      "Precision (Macro): 0.8157894736842105\n",
      "Recall (Macro): 0.6111111111111112\n",
      "F1 Score (Macro): 0.5689149560117301\n",
      "F1 Score (Micro): 0.6666666666666666\n",
      "Confusion Matrix:\n",
      "[[12  0]\n",
      " [ 7  2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      1.00      0.77        12\n",
      "           1       1.00      0.22      0.36         9\n",
      "\n",
      "    accuracy                           0.67        21\n",
      "   macro avg       0.82      0.61      0.57        21\n",
      "weighted avg       0.79      0.67      0.60        21\n",
      "\n",
      "\n",
      "Naive Bayes:\n",
      "Accuracy: 0.5714285714285714\n",
      "Precision (Macro): 0.2857142857142857\n",
      "Recall (Macro): 0.5\n",
      "F1 Score (Macro): 0.36363636363636365\n",
      "F1 Score (Micro): 0.5714285714285714\n",
      "Confusion Matrix:\n",
      "[[12  0]\n",
      " [ 9  0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73        12\n",
      "           1       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.57        21\n",
      "   macro avg       0.29      0.50      0.36        21\n",
      "weighted avg       0.33      0.57      0.42        21\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Evaluating label: major_diabetes\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.7619047619047619\n",
      "Precision (Macro): 0.868421052631579\n",
      "Recall (Macro): 0.6428571428571428\n",
      "F1 Score (Macro): 0.6464646464646464\n",
      "F1 Score (Micro): 0.7619047619047619\n",
      "Confusion Matrix:\n",
      "[[ 2  5]\n",
      " [ 0 14]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.29      0.44         7\n",
      "           1       0.74      1.00      0.85        14\n",
      "\n",
      "    accuracy                           0.76        21\n",
      "   macro avg       0.87      0.64      0.65        21\n",
      "weighted avg       0.82      0.76      0.71        21\n",
      "\n",
      "\n",
      "Linear SVM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7142857142857143\n",
      "Precision (Macro): 0.675\n",
      "Recall (Macro): 0.6428571428571428\n",
      "F1 Score (Macro): 0.6499999999999999\n",
      "F1 Score (Micro): 0.7142857142857143\n",
      "Confusion Matrix:\n",
      "[[ 3  4]\n",
      " [ 2 12]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.43      0.50         7\n",
      "           1       0.75      0.86      0.80        14\n",
      "\n",
      "    accuracy                           0.71        21\n",
      "   macro avg       0.68      0.64      0.65        21\n",
      "weighted avg       0.70      0.71      0.70        21\n",
      "\n",
      "\n",
      "Naive Bayes:\n",
      "Accuracy: 0.6666666666666666\n",
      "Precision (Macro): 0.3333333333333333\n",
      "Recall (Macro): 0.5\n",
      "F1 Score (Macro): 0.4\n",
      "F1 Score (Micro): 0.6666666666666666\n",
      "Confusion Matrix:\n",
      "[[ 0  7]\n",
      " [ 0 14]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.67      1.00      0.80        14\n",
      "\n",
      "    accuracy                           0.67        21\n",
      "   macro avg       0.33      0.50      0.40        21\n",
      "weighted avg       0.44      0.67      0.53        21\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Main function to load data, train and evaluate models for each label\n",
    "labels = ['abdominal', 'creatinine', 'major_diabetes']\n",
    "\n",
    "for label in labels:\n",
    "    print(f\"Evaluating label: {label}\")\n",
    "    y_train = train_df[label]\n",
    "    y_test = test_df[label]\n",
    "        \n",
    "    print(\"\\nLogistic Regression:\")\n",
    "    lr_model = LogisticRegression(max_iter=1000)\n",
    "    train_evaluate_model(X_train, X_test, y_train, y_test, lr_model)\n",
    "        \n",
    "    print(\"\\nLinear SVM:\")\n",
    "    svm_model = SVC(kernel='linear')\n",
    "    train_evaluate_model(X_train, X_test, y_train, y_test, svm_model)\n",
    "        \n",
    "    print(\"\\nNaive Bayes:\")\n",
    "    nb_model = MultinomialNB()\n",
    "    train_evaluate_model(X_train, X_test, y_train, y_test, nb_model)\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
