{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with Logistic Regression, Linear SVM, and Naive Bayes\n",
    "This notebook reads training and testing data from CSV files, preprocesses the text data, and performs classification using Logistic Regression, Linear SVM, and Naive Bayes with TF-IDF vectors. It reports the macro and micro F1 scores, accuracy, precision, recall, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\r4hei\\miniconda3\\envs\\nlp\\lib\\site-packages (from scikit-learn) (3.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data\n",
    "train_df = pd.read_csv('Dataset/preprocessed/part1/train.csv')\n",
    "val_df = pd.read_csv('Dataset/preprocessed/part1/val.csv')\n",
    "test_df = pd.read_csv('Dataset/preprocessed/part1/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 20, 21)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberize_labels(df, labels):\n",
    "    for label in labels:\n",
    "        df[label] = df[label].apply(lambda x: 1 if x == 'met' else 0)\n",
    "    return df\n",
    "\n",
    "train_df = numberize_labels(train_df, labels=['abdominal', 'creatinine', 'major_diabetes'])\n",
    "test_df = numberize_labels(test_df, labels=['abdominal', 'creatinine', 'major_diabetes'])\n",
    "val_df = numberize_labels(val_df, labels=['abdominal', 'creatinine', 'major_diabetes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine train and val for this part\n",
    "train_df = pd.concat([train_df, val_df], ignore_index=True)\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess and vectorize text data\n",
    "def preprocess_data(train_df, test_df, text_column):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train = vectorizer.fit_transform(train_df[text_column])\n",
    "    X_test = vectorizer.transform(test_df[text_column])\n",
    "    return X_train, X_test, vectorizer\n",
    "\n",
    "# Preprocess data\n",
    "# X_train, X_test, vectorizer = preprocess_data(train_df, test_df, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate model\n",
    "def train_evaluate_model(X_train, X_test, y_train, y_test, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(preds, labels):\n",
    "    # preds = preds.int().numpy()\n",
    "    labels = labels.to_numpy()\n",
    "    # print(labels.shape, preds.shape)\n",
    "\n",
    "    \n",
    "    # Initialize counts\n",
    "    tp = np.zeros((3,))\n",
    "    tn = np.zeros((3,))\n",
    "    fp = np.zeros((3,))\n",
    "    fn = np.zeros((3,))\n",
    "    \n",
    "    for i in range(3):\n",
    "        tp[i] = np.sum((preds[:, i] == 1) & (labels[:, i] == 1))\n",
    "        tn[i] = np.sum((preds[:, i] == 0) & (labels[:, i] == 0))\n",
    "        fp[i] = np.sum((preds[:, i] == 1) & (labels[:, i] == 0))\n",
    "        fn[i] = np.sum((preds[:, i] == 0) & (labels[:, i] == 1))\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision = tp / (tp + fp + 1e-10)\n",
    "    recall = tp / (tp + fn + 1e-10)\n",
    "    micro_f1 = 2 * np.sum(tp) / (2 * np.sum(tp) + np.sum(fp) + np.sum(fn) + 1e-10)\n",
    "    macro_f1 = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels.flatten(), preds.flatten()),\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'micro_f1': micro_f1,\n",
    "        'macro_f1': np.mean(macro_f1),\n",
    "        'confusion_matrix': confusion_matrix(labels.flatten(), preds.flatten())\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to load data, train and evaluate models for each label\n",
    "\n",
    "labels = ['abdominal', 'creatinine', 'major_diabetes']\n",
    "\n",
    "def create_models_and_eval(train_df, test_df, C=1.0):\n",
    "    preds_lr = np.zeros((len(test_df), len(labels)))\n",
    "    preds_svm = np.zeros((len(test_df), len(labels)))\n",
    "    preds_nb = np.zeros((len(test_df), len(labels)))\n",
    "    X_train, X_test, vectorizer = preprocess_data(train_df, test_df, 'text')\n",
    "\n",
    "\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        y_train = train_df[label]\n",
    "        y_test = test_df[label]\n",
    "            \n",
    "        # lr_model = LogisticRegression(max_iter=1000)\n",
    "        # preds_lr[:, i] = train_evaluate_model(X_train, X_test, y_train, y_test, lr_model)\n",
    "            \n",
    "        svm_model = SVC(kernel='linear', C = C)\n",
    "        preds_svm[:, i] = train_evaluate_model(X_train, X_test, y_train, y_test, svm_model)\n",
    "            \n",
    "        # nb_model = MultinomialNB()\n",
    "        # preds_nb[:, i] = train_evaluate_model(X_train, X_test, y_train, y_test, nb_model)\n",
    "    \n",
    "    # print(\"Logistic Regression Evaluation\")\n",
    "    # print(compute_metrics(preds_lr, test_df[labels]))\n",
    "\n",
    "    return compute_metrics(preds_svm, test_df[labels])\n",
    "    # print(\"Naive Bayes Evaluation\")\n",
    "    # print(compute_metrics(preds_nb, test_df[labels]))  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Evaluation. C =  0.1\n",
      "{'accuracy': 0.5894394394394394, 'precision': array([0.        , 0.        , 0.54744745]), 'recall': array([0., 0., 1.]), 'micro_f1': 0.47012422823174854, 'macro_f1': 0.23499118164184885, 'confusion_matrix': array([[221,  82],\n",
      "       [141,  99]], dtype=int64)}\n",
      "SVM Evaluation. C =  0.5\n",
      "{'accuracy': 0.5931431431431432, 'precision': array([0.        , 0.        , 0.55529058]), 'recall': array([0., 0., 1.]), 'micro_f1': 0.4725484706559856, 'macro_f1': 0.23683026210157224, 'confusion_matrix': array([[223,  80],\n",
      "       [141,  99]], dtype=int64)}\n",
      "SVM Evaluation. C =  5\n",
      "{'accuracy': 0.6778278278278277, 'precision': array([0.55656566, 0.68686869, 0.67180576]), 'recall': array([0.42846908, 0.50371785, 0.84980392]), 'micro_f1': 0.628745794328068, 'macro_f1': 0.5958786890458901, 'confusion_matrix': array([[220,  83],\n",
      "       [ 92, 148]], dtype=int64)}\n",
      "SVM Evaluation. C =  10\n",
      "{'accuracy': 0.6778278278278277, 'precision': array([0.55656566, 0.68686869, 0.67180576]), 'recall': array([0.42846908, 0.50371785, 0.84980392]), 'micro_f1': 0.628745794328068, 'macro_f1': 0.5958786890458901, 'confusion_matrix': array([[220,  83],\n",
      "       [ 92, 148]], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "# k fold cross validation\n",
    "for C in [0.1, 0.5, 5, 10]:\n",
    "    k = 5\n",
    "    folds = np.array_split(train_df, k)\n",
    "    metrics = {}\n",
    "    for i in range(k):\n",
    "        new_train_df = pd.concat([fold for j, fold in enumerate(folds) if j != i], ignore_index=True)\n",
    "        val_df = folds[i]\n",
    "        metrics_i = create_models_and_eval(new_train_df, val_df, C=C)\n",
    "        for key in metrics_i.keys():\n",
    "            if key in metrics:\n",
    "                metrics[key] += metrics_i[key]\n",
    "            else:\n",
    "                metrics[key] = metrics_i[key]\n",
    "    for key in metrics.keys():\n",
    "        if key != 'confusion_matrix':\n",
    "            metrics[key] /= k\n",
    "    \n",
    "    print(\"SVM Evaluation. C = \", C)\n",
    "    print(metrics)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Evaluation on Test set on C=5\n",
      "{'accuracy': 0.7301587301587301, 'precision': array([0.58333333, 1.        , 0.73333333]), 'recall': array([0.77777778, 0.66666667, 0.78571429]), 'micro_f1': 0.7384615384604023, 'macro_f1': 0.7417624520508904, 'confusion_matrix': array([[22,  9],\n",
      "       [ 8, 24]], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "# so we pick C = 5\n",
    "\n",
    "metrics = create_models_and_eval(train_df, test_df, C=5)\n",
    "print('SVM Evaluation on Test set on C=5')\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
