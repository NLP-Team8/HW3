{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re, string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n"
     ]
    }
   ],
   "source": [
    "path = \"Dataset/n2c2/part1/\"\n",
    "files = [f for f in listdir(path=path) if isfile(join(path, f))]\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str, lowercase=True, stopword_removal=True, stopwords_domain=[], min_length=2,  punctuation_removal=True,\n",
    "                    does_stem=False, does_lemm=False):\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    if punctuation_removal:\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    if stopword_removal:\n",
    "        stop_words = set(stopwords.words('english') + stopwords_domain)\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "    if does_stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(word) for word in tokens]\n",
    "    if does_lemm:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    tokens = [word for word in tokens if len(word) >= min_length]\n",
    "\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Data: 100%|██████████| 202/202 [00:00<00:00, 205.53it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for f_name in tqdm(files, desc=\"Extracting Data\"):\n",
    "    tree = ET.parse(path + f_name)\n",
    "    root = tree.getroot()\n",
    "    entry = {}\n",
    "    text = root.find(\"TEXT\")\n",
    "    entry['text'] = preprocess_text(text=text.text, lowercase=True, stopword_removal=True, min_length=2, punctuation_removal=True,\n",
    "                                    does_lemm=False, does_stem=False)\n",
    "    tags = root.find(\"TAGS\")   \n",
    "    major_diabetes = tags.find(\"MAJOR-DIABETES\")\n",
    "    entry[\"major_diabetes\"] = major_diabetes.attrib.get(\"met\")\n",
    "    abdominal = tags.find(\"ABDOMINAL\")\n",
    "    entry[\"abdominal\"] = abdominal.attrib.get(\"met\")\n",
    "    creatinine = tags.find(\"CREATININE\")\n",
    "    entry[\"creatinine\"] = creatinine.attrib.get(\"met\")\n",
    "\n",
    "    dataset.append(entry)\n",
    "\n",
    "\n",
    "###  just for checking ####\n",
    "# print(dataset[1][\"abdominal\"])\n",
    "# print(dataset[1][\"major_diabetes\"])\n",
    "# print(dataset[1][\"creatinine\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>major_diabetes</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>creatinine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>record date 21430403 pl neurology promptcarele...</td>\n",
       "      <td>met</td>\n",
       "      <td>not met</td>\n",
       "      <td>not met</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>record date 21450813 august 12 2145 dr mabel d...</td>\n",
       "      <td>met</td>\n",
       "      <td>not met</td>\n",
       "      <td>met</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>record date 20880626 personal data overall hea...</td>\n",
       "      <td>met</td>\n",
       "      <td>met</td>\n",
       "      <td>not met</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>record date 20690917 office note andrew conner...</td>\n",
       "      <td>not met</td>\n",
       "      <td>not met</td>\n",
       "      <td>not met</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>record date 20910702 cardiology beauregard mem...</td>\n",
       "      <td>not met</td>\n",
       "      <td>not met</td>\n",
       "      <td>not met</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text major_diabetes abdominal  \\\n",
       "0  record date 21430403 pl neurology promptcarele...            met   not met   \n",
       "1  record date 21450813 august 12 2145 dr mabel d...            met   not met   \n",
       "2  record date 20880626 personal data overall hea...            met       met   \n",
       "3  record date 20690917 office note andrew conner...        not met   not met   \n",
       "4  record date 20910702 cardiology beauregard mem...        not met   not met   \n",
       "\n",
       "  creatinine  \n",
       "0    not met  \n",
       "1        met  \n",
       "2    not met  \n",
       "3    not met  \n",
       "4    not met  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Dataset/preprocessed/part1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
