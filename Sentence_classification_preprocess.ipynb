{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re, string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n"
     ]
    }
   ],
   "source": [
    "path = \"Dataset/n2c2/part1/\"\n",
    "files = [f for f in listdir(path=path) if isfile(join(path, f))]\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str, lowercase=True, stopword_removal=True, stopwords_domain=[], min_length=2,  punctuation_removal=True,\n",
    "                    does_stem=False, does_lemm=False):\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    if punctuation_removal:\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    if stopword_removal:\n",
    "        stop_words = set(stopwords.words('english') + stopwords_domain)\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "    if does_stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(word) for word in tokens]\n",
    "    if does_lemm:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    tokens = [word for word in tokens if len(word) >= min_length]\n",
    "\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Data: 100%|██████████| 202/202 [00:01<00:00, 140.79it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for f_name in tqdm(files, desc=\"Extracting Data\"):\n",
    "    tree = ET.parse(path + f_name)\n",
    "    root = tree.getroot()\n",
    "    entry = {}\n",
    "    text = root.find(\"TEXT\")\n",
    "    entry['text'] = preprocess_text(text=text.text, lowercase=True, stopword_removal=True, min_length=2, punctuation_removal=True,\n",
    "                                    does_lemm=False, does_stem=False)\n",
    "    tags = root.find(\"TAGS\")   \n",
    "    major_diabetes = tags.find(\"MAJOR-DIABETES\")\n",
    "    entry[\"major_diabetes\"] = major_diabetes.attrib.get(\"met\")\n",
    "    abdominal = tags.find(\"ABDOMINAL\")\n",
    "    entry[\"abdominal\"] = abdominal.attrib.get(\"met\")\n",
    "    creatinine = tags.find(\"CREATININE\")\n",
    "    entry[\"creatinine\"] = creatinine.attrib.get(\"met\")\n",
    "\n",
    "    dataset.append(entry)\n",
    "\n",
    "\n",
    "###  just for checking ####\n",
    "# print(dataset[1][\"abdominal\"])\n",
    "# print(dataset[1][\"major_diabetes\"])\n",
    "# print(dataset[1][\"creatinine\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>major_diabetes</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>creatinine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>record date 20631128 hpi 51 yo mmp comes estab...</td>\n",
       "      <td>met</td>\n",
       "      <td>met</td>\n",
       "      <td>not met</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>record date 20940129 internal medicine associa...</td>\n",
       "      <td>met</td>\n",
       "      <td>not met</td>\n",
       "      <td>met</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>record date 21210331 kern medical center pread...</td>\n",
       "      <td>met</td>\n",
       "      <td>met</td>\n",
       "      <td>met</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>record date 20691118 mr gallegos comes clinic ...</td>\n",
       "      <td>met</td>\n",
       "      <td>not met</td>\n",
       "      <td>not met</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>record date 20870221 dameron emergency dept vi...</td>\n",
       "      <td>met</td>\n",
       "      <td>met</td>\n",
       "      <td>not met</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text major_diabetes abdominal  \\\n",
       "0  record date 20631128 hpi 51 yo mmp comes estab...            met       met   \n",
       "1  record date 20940129 internal medicine associa...            met   not met   \n",
       "2  record date 21210331 kern medical center pread...            met       met   \n",
       "3  record date 20691118 mr gallegos comes clinic ...            met   not met   \n",
       "4  record date 20870221 dameron emergency dept vi...            met       met   \n",
       "\n",
       "  creatinine  \n",
       "0    not met  \n",
       "1        met  \n",
       "2        met  \n",
       "3    not met  \n",
       "4    not met  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Dataset/preprocessed/part1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dataset/preprocessed/part1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>major_diabetes</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>creatinine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>record date 20631128 hpi 51 yo mmp comes estab...</td>\n",
       "      <td>met</td>\n",
       "      <td>met</td>\n",
       "      <td>not met</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>record date 20940129 internal medicine associa...</td>\n",
       "      <td>met</td>\n",
       "      <td>not met</td>\n",
       "      <td>met</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>record date 21210331 kern medical center pread...</td>\n",
       "      <td>met</td>\n",
       "      <td>met</td>\n",
       "      <td>met</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>record date 20691118 mr gallegos comes clinic ...</td>\n",
       "      <td>met</td>\n",
       "      <td>not met</td>\n",
       "      <td>not met</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>record date 20870221 dameron emergency dept vi...</td>\n",
       "      <td>met</td>\n",
       "      <td>met</td>\n",
       "      <td>not met</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text major_diabetes abdominal  \\\n",
       "0  record date 20631128 hpi 51 yo mmp comes estab...            met       met   \n",
       "1  record date 20940129 internal medicine associa...            met   not met   \n",
       "2  record date 21210331 kern medical center pread...            met       met   \n",
       "3  record date 20691118 mr gallegos comes clinic ...            met   not met   \n",
       "4  record date 20870221 dameron emergency dept vi...            met       met   \n",
       "\n",
       "  creatinine  \n",
       "0    not met  \n",
       "1        met  \n",
       "2        met  \n",
       "3    not met  \n",
       "4    not met  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "test_size = 0.1\n",
    "validation_size = 0.1\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size= 1 - train_size, random_state=42, shuffle=True)\n",
    "val_df, test_df = train_test_split(temp_df, test_size= test_size / (test_size + validation_size), random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size : 161/202 = 0.7970297029702971\n",
      "test size : 21/202 = 0.10396039603960396\n",
      "val size : 20/202 = 0.10396039603960396\n"
     ]
    }
   ],
   "source": [
    "len_total = len(train_df) + len(val_df ) + len(test_df)\n",
    "print(f\"train size : {len(train_df)}/{len_total} = {len(train_df)/len_total}\")\n",
    "print(f\"test size : {len(test_df)}/{len_total} = {len(test_df)/len_total}\")\n",
    "print(f\"val size : {len(val_df)}/{len_total} = {len(test_df)/len_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"Dataset/preprocessed/part1/train.csv\", index=False)\n",
    "val_df.to_csv(\"Dataset/preprocessed/part1/val.csv\", index=False)\n",
    "test_df.to_csv(\"Dataset/preprocessed/part1/test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
